{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "import libraries"
      ],
      "metadata": {
        "id": "WO7ZcxetLJlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "FbmgpqkBLKia"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Data"
      ],
      "metadata": {
        "id": "-f1LunMPLaKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "5-HnNsMNLXVD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgNW4lWmNMoJ",
        "outputId": "cb374759-f542-4db6-9ae8-4d1888144000"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkyzzf--NTa8",
        "outputId": "02f386b4-1c4a-46a4-9229-c59187e95620"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('emotions.csv')"
      ],
      "metadata": {
        "id": "8LchdKRPNlZs"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "09bAlfetN0-P",
        "outputId": "f158fe79-1a3c-4a9d-f44b-4947d67aab0d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
              "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
              "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
              "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
              "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
              "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
              "\n",
              "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
              "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
              "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
              "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
              "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
              "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
              "\n",
              "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b     label  \n",
              "0       23.5     -215.0     280.00    -162.00    -162.00     280.00  NEGATIVE  \n",
              "1      -23.3      182.0       2.57     -31.60     -31.60       2.57   NEUTRAL  \n",
              "2      462.0     -267.0     281.00    -148.00    -148.00     281.00  POSITIVE  \n",
              "3      299.0      132.0     -12.40       9.53       9.53     -12.40  POSITIVE  \n",
              "4       12.0      119.0     -17.60      23.90      23.90     -17.60   NEUTRAL  \n",
              "\n",
              "[5 rows x 2549 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa98498f-221d-4e7b-83e2-455d45021a08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># mean_0_a</th>\n",
              "      <th>mean_1_a</th>\n",
              "      <th>mean_2_a</th>\n",
              "      <th>mean_3_a</th>\n",
              "      <th>mean_4_a</th>\n",
              "      <th>mean_d_0_a</th>\n",
              "      <th>mean_d_1_a</th>\n",
              "      <th>mean_d_2_a</th>\n",
              "      <th>mean_d_3_a</th>\n",
              "      <th>mean_d_4_a</th>\n",
              "      <th>...</th>\n",
              "      <th>fft_741_b</th>\n",
              "      <th>fft_742_b</th>\n",
              "      <th>fft_743_b</th>\n",
              "      <th>fft_744_b</th>\n",
              "      <th>fft_745_b</th>\n",
              "      <th>fft_746_b</th>\n",
              "      <th>fft_747_b</th>\n",
              "      <th>fft_748_b</th>\n",
              "      <th>fft_749_b</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.62</td>\n",
              "      <td>30.3</td>\n",
              "      <td>-356.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>26.3</td>\n",
              "      <td>1.070</td>\n",
              "      <td>0.411</td>\n",
              "      <td>-15.70</td>\n",
              "      <td>2.06</td>\n",
              "      <td>3.15</td>\n",
              "      <td>...</td>\n",
              "      <td>23.5</td>\n",
              "      <td>20.3</td>\n",
              "      <td>20.3</td>\n",
              "      <td>23.5</td>\n",
              "      <td>-215.0</td>\n",
              "      <td>280.00</td>\n",
              "      <td>-162.00</td>\n",
              "      <td>-162.00</td>\n",
              "      <td>280.00</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.80</td>\n",
              "      <td>33.1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>25.8</td>\n",
              "      <td>22.8</td>\n",
              "      <td>6.550</td>\n",
              "      <td>1.680</td>\n",
              "      <td>2.88</td>\n",
              "      <td>3.83</td>\n",
              "      <td>-4.82</td>\n",
              "      <td>...</td>\n",
              "      <td>-23.3</td>\n",
              "      <td>-21.8</td>\n",
              "      <td>-21.8</td>\n",
              "      <td>-23.3</td>\n",
              "      <td>182.0</td>\n",
              "      <td>2.57</td>\n",
              "      <td>-31.60</td>\n",
              "      <td>-31.60</td>\n",
              "      <td>2.57</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.90</td>\n",
              "      <td>29.4</td>\n",
              "      <td>-416.0</td>\n",
              "      <td>16.7</td>\n",
              "      <td>23.7</td>\n",
              "      <td>79.900</td>\n",
              "      <td>3.360</td>\n",
              "      <td>90.20</td>\n",
              "      <td>89.90</td>\n",
              "      <td>2.03</td>\n",
              "      <td>...</td>\n",
              "      <td>462.0</td>\n",
              "      <td>-233.0</td>\n",
              "      <td>-233.0</td>\n",
              "      <td>462.0</td>\n",
              "      <td>-267.0</td>\n",
              "      <td>281.00</td>\n",
              "      <td>-148.00</td>\n",
              "      <td>-148.00</td>\n",
              "      <td>281.00</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.90</td>\n",
              "      <td>31.6</td>\n",
              "      <td>-143.0</td>\n",
              "      <td>19.8</td>\n",
              "      <td>24.3</td>\n",
              "      <td>-0.584</td>\n",
              "      <td>-0.284</td>\n",
              "      <td>8.82</td>\n",
              "      <td>2.30</td>\n",
              "      <td>-1.97</td>\n",
              "      <td>...</td>\n",
              "      <td>299.0</td>\n",
              "      <td>-243.0</td>\n",
              "      <td>-243.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>-12.40</td>\n",
              "      <td>9.53</td>\n",
              "      <td>9.53</td>\n",
              "      <td>-12.40</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28.30</td>\n",
              "      <td>31.3</td>\n",
              "      <td>45.2</td>\n",
              "      <td>27.3</td>\n",
              "      <td>24.5</td>\n",
              "      <td>34.800</td>\n",
              "      <td>-5.790</td>\n",
              "      <td>3.06</td>\n",
              "      <td>41.40</td>\n",
              "      <td>5.52</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>38.1</td>\n",
              "      <td>38.1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>-17.60</td>\n",
              "      <td>23.90</td>\n",
              "      <td>23.90</td>\n",
              "      <td>-17.60</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2549 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa98498f-221d-4e7b-83e2-455d45021a08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa98498f-221d-4e7b-83e2-455d45021a08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa98498f-221d-4e7b-83e2-455d45021a08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c0ea0d3d-14ab-474b-9219-e7e8b782b081\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0ea0d3d-14ab-474b-9219-e7e8b782b081')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c0ea0d3d-14ab-474b-9219-e7e8b782b081 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "lXT8-c7-PCqx",
        "outputId": "f62e9975-c23b-44cb-f55b-b326a30915f3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label\n",
              "NEUTRAL     716\n",
              "NEGATIVE    708\n",
              "POSITIVE    708\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>NEUTRAL</th>\n",
              "      <td>716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NEGATIVE</th>\n",
              "      <td>708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>POSITIVE</th>\n",
              "      <td>708</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wp9LJXg5PK5e",
        "outputId": "c6351139-3bfd-43d9-eb22-47220bc2d6c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2132 entries, 0 to 2131\n",
            "Columns: 2549 entries, # mean_0_a to label\n",
            "dtypes: float64(2548), object(1)\n",
            "memory usage: 41.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_maping = {'NEGATIVE': 0, 'NEUTRAL': 1, 'POSITIVE': 2}"
      ],
      "metadata": {
        "id": "ow-raezwPPbm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'] = data['label'].replace(label_maping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15eLHc5DPTAW",
        "outputId": "47222d3a-b16f-4b08-b2a6-18abf75e2971"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2558762912.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  data['label'] = data['label'].replace(label_maping)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "HmsGMwKGPVOj",
        "outputId": "790a1514-5155-41fc-eb73-09567d09ed24"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   # mean_0_a  mean_1_a  mean_2_a  mean_3_a  mean_4_a  mean_d_0_a  mean_d_1_a  \\\n",
              "0        4.62      30.3    -356.0      15.6      26.3       1.070       0.411   \n",
              "1       28.80      33.1      32.0      25.8      22.8       6.550       1.680   \n",
              "2        8.90      29.4    -416.0      16.7      23.7      79.900       3.360   \n",
              "3       14.90      31.6    -143.0      19.8      24.3      -0.584      -0.284   \n",
              "4       28.30      31.3      45.2      27.3      24.5      34.800      -5.790   \n",
              "\n",
              "   mean_d_2_a  mean_d_3_a  mean_d_4_a  ...  fft_741_b  fft_742_b  fft_743_b  \\\n",
              "0      -15.70        2.06        3.15  ...       23.5       20.3       20.3   \n",
              "1        2.88        3.83       -4.82  ...      -23.3      -21.8      -21.8   \n",
              "2       90.20       89.90        2.03  ...      462.0     -233.0     -233.0   \n",
              "3        8.82        2.30       -1.97  ...      299.0     -243.0     -243.0   \n",
              "4        3.06       41.40        5.52  ...       12.0       38.1       38.1   \n",
              "\n",
              "   fft_744_b  fft_745_b  fft_746_b  fft_747_b  fft_748_b  fft_749_b  label  \n",
              "0       23.5     -215.0     280.00    -162.00    -162.00     280.00      0  \n",
              "1      -23.3      182.0       2.57     -31.60     -31.60       2.57      1  \n",
              "2      462.0     -267.0     281.00    -148.00    -148.00     281.00      2  \n",
              "3      299.0      132.0     -12.40       9.53       9.53     -12.40      2  \n",
              "4       12.0      119.0     -17.60      23.90      23.90     -17.60      1  \n",
              "\n",
              "[5 rows x 2549 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d1b9038-6d09-43c1-97e1-3a45ecb8efea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th># mean_0_a</th>\n",
              "      <th>mean_1_a</th>\n",
              "      <th>mean_2_a</th>\n",
              "      <th>mean_3_a</th>\n",
              "      <th>mean_4_a</th>\n",
              "      <th>mean_d_0_a</th>\n",
              "      <th>mean_d_1_a</th>\n",
              "      <th>mean_d_2_a</th>\n",
              "      <th>mean_d_3_a</th>\n",
              "      <th>mean_d_4_a</th>\n",
              "      <th>...</th>\n",
              "      <th>fft_741_b</th>\n",
              "      <th>fft_742_b</th>\n",
              "      <th>fft_743_b</th>\n",
              "      <th>fft_744_b</th>\n",
              "      <th>fft_745_b</th>\n",
              "      <th>fft_746_b</th>\n",
              "      <th>fft_747_b</th>\n",
              "      <th>fft_748_b</th>\n",
              "      <th>fft_749_b</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.62</td>\n",
              "      <td>30.3</td>\n",
              "      <td>-356.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>26.3</td>\n",
              "      <td>1.070</td>\n",
              "      <td>0.411</td>\n",
              "      <td>-15.70</td>\n",
              "      <td>2.06</td>\n",
              "      <td>3.15</td>\n",
              "      <td>...</td>\n",
              "      <td>23.5</td>\n",
              "      <td>20.3</td>\n",
              "      <td>20.3</td>\n",
              "      <td>23.5</td>\n",
              "      <td>-215.0</td>\n",
              "      <td>280.00</td>\n",
              "      <td>-162.00</td>\n",
              "      <td>-162.00</td>\n",
              "      <td>280.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>28.80</td>\n",
              "      <td>33.1</td>\n",
              "      <td>32.0</td>\n",
              "      <td>25.8</td>\n",
              "      <td>22.8</td>\n",
              "      <td>6.550</td>\n",
              "      <td>1.680</td>\n",
              "      <td>2.88</td>\n",
              "      <td>3.83</td>\n",
              "      <td>-4.82</td>\n",
              "      <td>...</td>\n",
              "      <td>-23.3</td>\n",
              "      <td>-21.8</td>\n",
              "      <td>-21.8</td>\n",
              "      <td>-23.3</td>\n",
              "      <td>182.0</td>\n",
              "      <td>2.57</td>\n",
              "      <td>-31.60</td>\n",
              "      <td>-31.60</td>\n",
              "      <td>2.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.90</td>\n",
              "      <td>29.4</td>\n",
              "      <td>-416.0</td>\n",
              "      <td>16.7</td>\n",
              "      <td>23.7</td>\n",
              "      <td>79.900</td>\n",
              "      <td>3.360</td>\n",
              "      <td>90.20</td>\n",
              "      <td>89.90</td>\n",
              "      <td>2.03</td>\n",
              "      <td>...</td>\n",
              "      <td>462.0</td>\n",
              "      <td>-233.0</td>\n",
              "      <td>-233.0</td>\n",
              "      <td>462.0</td>\n",
              "      <td>-267.0</td>\n",
              "      <td>281.00</td>\n",
              "      <td>-148.00</td>\n",
              "      <td>-148.00</td>\n",
              "      <td>281.00</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.90</td>\n",
              "      <td>31.6</td>\n",
              "      <td>-143.0</td>\n",
              "      <td>19.8</td>\n",
              "      <td>24.3</td>\n",
              "      <td>-0.584</td>\n",
              "      <td>-0.284</td>\n",
              "      <td>8.82</td>\n",
              "      <td>2.30</td>\n",
              "      <td>-1.97</td>\n",
              "      <td>...</td>\n",
              "      <td>299.0</td>\n",
              "      <td>-243.0</td>\n",
              "      <td>-243.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>-12.40</td>\n",
              "      <td>9.53</td>\n",
              "      <td>9.53</td>\n",
              "      <td>-12.40</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28.30</td>\n",
              "      <td>31.3</td>\n",
              "      <td>45.2</td>\n",
              "      <td>27.3</td>\n",
              "      <td>24.5</td>\n",
              "      <td>34.800</td>\n",
              "      <td>-5.790</td>\n",
              "      <td>3.06</td>\n",
              "      <td>41.40</td>\n",
              "      <td>5.52</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>38.1</td>\n",
              "      <td>38.1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>-17.60</td>\n",
              "      <td>23.90</td>\n",
              "      <td>23.90</td>\n",
              "      <td>-17.60</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2549 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d1b9038-6d09-43c1-97e1-3a45ecb8efea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4d1b9038-6d09-43c1-97e1-3a45ecb8efea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4d1b9038-6d09-43c1-97e1-3a45ecb8efea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3dfc24db-3640-4674-bb7c-74a6cda03197\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3dfc24db-3640-4674-bb7c-74a6cda03197')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3dfc24db-3640-4674-bb7c-74a6cda03197 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop('label', axis=1)\n",
        "y = data['label']"
      ],
      "metadata": {
        "id": "qXH1oBKjPZ5x"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "cKAb6f1mQmmm"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0pkR7tAwQoUp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
      ],
      "metadata": {
        "id": "pkm05EVeREl0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape X_Train:', X_train.shape)\n",
        "print('Shape y_Train:', y_train.shape)\n",
        "print('Shape X_Test:', X_test.shape)\n",
        "print('Shape y_Test:', y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAFq-fsERIJE",
        "outputId": "87715293-d130-48df-d82a-1c8e6852985b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape X_Train: (1492, 2548)\n",
            "Shape y_Train: (1492,)\n",
            "Shape X_Test: (640, 2548)\n",
            "Shape y_Test: (640,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = X_train.reshape(X_train, (1492,1, 2548))\n",
        "# X_test = X_test.reshape(X_test, (640,1,2548))\n",
        "X_train = X_train.reshape(-1, 1, 2548)\n",
        "X_test = X_test.reshape(-1, 1, 2548)"
      ],
      "metadata": {
        "id": "DXGdJxwLQjVq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "ryj13CWnROQ0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, activation='relu', input_shape=(1, 2548), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(32, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L7XquKjSZJN",
        "outputId": "f786f576-954d-4d26-cb56-185c2087a5ac"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "1nobASwCawih",
        "outputId": "e4742f86-1089-471d-efcd-6956f1f01a80"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │       \u001b[38;5;34m668,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">668,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m681,443\u001b[0m (2.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">681,443</span> (2.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m681,443\u001b[0m (2.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">681,443</span> (2.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "W353Tt7WazvA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qcwl2_Xbjda",
        "outputId": "1a89ae3b-d981-4b94-d6fa-ac578b9e0dea"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 70ms/step - accuracy: 0.7338 - loss: 0.6557 - val_accuracy: 0.9219 - val_loss: 0.3036\n",
            "Epoch 2/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9058 - loss: 0.2563 - val_accuracy: 0.9328 - val_loss: 0.2128\n",
            "Epoch 3/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.1914 - val_accuracy: 0.9547 - val_loss: 0.1809\n",
            "Epoch 4/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.1186 - val_accuracy: 0.9266 - val_loss: 0.1681\n",
            "Epoch 5/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9562 - loss: 0.0852 - val_accuracy: 0.9453 - val_loss: 0.1632\n",
            "Epoch 6/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9725 - loss: 0.0745 - val_accuracy: 0.9406 - val_loss: 0.1452\n",
            "Epoch 7/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.0735 - val_accuracy: 0.9500 - val_loss: 0.1484\n",
            "Epoch 8/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9748 - loss: 0.0764 - val_accuracy: 0.9594 - val_loss: 0.1433\n",
            "Epoch 9/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.0516 - val_accuracy: 0.9344 - val_loss: 0.1944\n",
            "Epoch 10/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.0462 - val_accuracy: 0.9531 - val_loss: 0.1538\n",
            "Epoch 11/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.0542 - val_accuracy: 0.9703 - val_loss: 0.1251\n",
            "Epoch 12/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0271 - val_accuracy: 0.9531 - val_loss: 0.1800\n",
            "Epoch 13/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0425 - val_accuracy: 0.9672 - val_loss: 0.1348\n",
            "Epoch 14/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0588 - val_accuracy: 0.9734 - val_loss: 0.1250\n",
            "Epoch 15/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0200 - val_accuracy: 0.9688 - val_loss: 0.1596\n",
            "Epoch 16/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0298 - val_accuracy: 0.9609 - val_loss: 0.1729\n",
            "Epoch 17/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0362 - val_accuracy: 0.9578 - val_loss: 0.2097\n",
            "Epoch 18/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0071 - val_accuracy: 0.9625 - val_loss: 0.1906\n",
            "Epoch 19/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0255 - val_accuracy: 0.9641 - val_loss: 0.1608\n",
            "Epoch 20/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0216 - val_accuracy: 0.9672 - val_loss: 0.1467\n",
            "Epoch 21/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0095 - val_accuracy: 0.9719 - val_loss: 0.1430\n",
            "Epoch 22/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0199 - val_accuracy: 0.9531 - val_loss: 0.2012\n",
            "Epoch 23/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0222 - val_accuracy: 0.9688 - val_loss: 0.1303\n",
            "Epoch 24/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.0151 - val_accuracy: 0.9594 - val_loss: 0.1361\n",
            "Epoch 25/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0246 - val_accuracy: 0.9766 - val_loss: 0.1100\n",
            "Epoch 26/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0289 - val_accuracy: 0.9797 - val_loss: 0.1156\n",
            "Epoch 27/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0227 - val_accuracy: 0.9797 - val_loss: 0.1097\n",
            "Epoch 28/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0216 - val_accuracy: 0.9766 - val_loss: 0.1007\n",
            "Epoch 29/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0130 - val_accuracy: 0.9625 - val_loss: 0.1660\n",
            "Epoch 30/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9905 - loss: 0.0244 - val_accuracy: 0.9719 - val_loss: 0.1439\n",
            "Epoch 31/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0109 - val_accuracy: 0.9688 - val_loss: 0.1336\n",
            "Epoch 32/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9978 - loss: 0.0143 - val_accuracy: 0.9656 - val_loss: 0.1732\n",
            "Epoch 33/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9971 - loss: 0.0086 - val_accuracy: 0.9797 - val_loss: 0.0919\n",
            "Epoch 34/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9937 - loss: 0.0167 - val_accuracy: 0.9734 - val_loss: 0.1394\n",
            "Epoch 35/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0127 - val_accuracy: 0.9609 - val_loss: 0.2228\n",
            "Epoch 36/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0242 - val_accuracy: 0.9703 - val_loss: 0.1551\n",
            "Epoch 37/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9953 - loss: 0.0144 - val_accuracy: 0.9781 - val_loss: 0.1474\n",
            "Epoch 38/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0143 - val_accuracy: 0.9750 - val_loss: 0.1339\n",
            "Epoch 39/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0050 - val_accuracy: 0.9750 - val_loss: 0.1645\n",
            "Epoch 40/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0031 - val_accuracy: 0.9797 - val_loss: 0.1559\n",
            "Epoch 41/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9967 - loss: 0.0169 - val_accuracy: 0.9781 - val_loss: 0.1331\n",
            "Epoch 42/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 0.0335 - val_accuracy: 0.9781 - val_loss: 0.1240\n",
            "Epoch 43/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0253 - val_accuracy: 0.9859 - val_loss: 0.1335\n",
            "Epoch 44/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0130 - val_accuracy: 0.9531 - val_loss: 0.2674\n",
            "Epoch 45/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.0231 - val_accuracy: 0.9766 - val_loss: 0.1378\n",
            "Epoch 46/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0203 - val_accuracy: 0.9688 - val_loss: 0.1440\n",
            "Epoch 47/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0173 - val_accuracy: 0.9719 - val_loss: 0.1678\n",
            "Epoch 48/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0096 - val_accuracy: 0.9766 - val_loss: 0.1058\n",
            "Epoch 49/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0163 - val_accuracy: 0.9641 - val_loss: 0.2107\n",
            "Epoch 50/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0174 - val_accuracy: 0.9703 - val_loss: 0.1845\n",
            "Epoch 51/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0095 - val_accuracy: 0.9703 - val_loss: 0.1851\n",
            "Epoch 52/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0102 - val_accuracy: 0.9812 - val_loss: 0.1471\n",
            "Epoch 53/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0033 - val_accuracy: 0.9797 - val_loss: 0.1654\n",
            "Epoch 54/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0061 - val_accuracy: 0.9734 - val_loss: 0.1778\n",
            "Epoch 55/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0061 - val_accuracy: 0.9781 - val_loss: 0.1806\n",
            "Epoch 56/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0058 - val_accuracy: 0.9766 - val_loss: 0.2044\n",
            "Epoch 57/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0395 - val_accuracy: 0.9781 - val_loss: 0.1478\n",
            "Epoch 58/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0128 - val_accuracy: 0.9656 - val_loss: 0.2239\n",
            "Epoch 59/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0084 - val_accuracy: 0.9719 - val_loss: 0.2354\n",
            "Epoch 60/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0182 - val_accuracy: 0.9719 - val_loss: 0.2140\n",
            "Epoch 61/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0142 - val_accuracy: 0.9766 - val_loss: 0.1770\n",
            "Epoch 62/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0072 - val_accuracy: 0.9750 - val_loss: 0.1563\n",
            "Epoch 63/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0116 - val_accuracy: 0.9734 - val_loss: 0.1587\n",
            "Epoch 64/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0092 - val_accuracy: 0.9750 - val_loss: 0.1881\n",
            "Epoch 65/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0051 - val_accuracy: 0.9781 - val_loss: 0.1811\n",
            "Epoch 66/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0056 - val_accuracy: 0.9734 - val_loss: 0.1920\n",
            "Epoch 67/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0079 - val_accuracy: 0.9797 - val_loss: 0.1840\n",
            "Epoch 68/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9781 - val_loss: 0.1873\n",
            "Epoch 69/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0296 - val_accuracy: 0.9734 - val_loss: 0.1861\n",
            "Epoch 70/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0195 - val_accuracy: 0.9703 - val_loss: 0.2665\n",
            "Epoch 71/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0029 - val_accuracy: 0.9812 - val_loss: 0.2288\n",
            "Epoch 72/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0095 - val_accuracy: 0.9547 - val_loss: 0.3913\n",
            "Epoch 73/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0396 - val_accuracy: 0.9656 - val_loss: 0.2653\n",
            "Epoch 74/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 0.9734 - val_loss: 0.1860\n",
            "Epoch 75/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.9750 - val_loss: 0.2030\n",
            "Epoch 76/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.1246e-04 - val_accuracy: 0.9797 - val_loss: 0.1967\n",
            "Epoch 77/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9766 - val_loss: 0.2233\n",
            "Epoch 78/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0051 - val_accuracy: 0.9672 - val_loss: 0.2237\n",
            "Epoch 79/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.1086 - val_accuracy: 0.9672 - val_loss: 0.2278\n",
            "Epoch 80/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0121 - val_accuracy: 0.9594 - val_loss: 0.3168\n",
            "Epoch 81/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9924 - loss: 0.0138 - val_accuracy: 0.9688 - val_loss: 0.2457\n",
            "Epoch 82/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0088 - val_accuracy: 0.9719 - val_loss: 0.2325\n",
            "Epoch 83/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0053 - val_accuracy: 0.9672 - val_loss: 0.2427\n",
            "Epoch 84/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.8283e-04 - val_accuracy: 0.9750 - val_loss: 0.2111\n",
            "Epoch 85/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0030 - val_accuracy: 0.9672 - val_loss: 0.2299\n",
            "Epoch 86/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9973 - loss: 0.0099 - val_accuracy: 0.9797 - val_loss: 0.1896\n",
            "Epoch 87/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 7.3374e-04 - val_accuracy: 0.9812 - val_loss: 0.2008\n",
            "Epoch 88/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9812 - val_loss: 0.2041\n",
            "Epoch 89/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.9872e-04 - val_accuracy: 0.9812 - val_loss: 0.2175\n",
            "Epoch 90/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 8.4504e-04 - val_accuracy: 0.9828 - val_loss: 0.2468\n",
            "Epoch 91/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0033 - val_accuracy: 0.9734 - val_loss: 0.2844\n",
            "Epoch 92/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9734 - val_loss: 0.3320\n",
            "Epoch 93/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0458 - val_accuracy: 0.9734 - val_loss: 0.2886\n",
            "Epoch 94/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0188 - val_accuracy: 0.9797 - val_loss: 0.2456\n",
            "Epoch 95/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0054 - val_accuracy: 0.9688 - val_loss: 0.3138\n",
            "Epoch 96/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9750 - val_loss: 0.2610\n",
            "Epoch 97/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9976 - loss: 0.0034 - val_accuracy: 0.9781 - val_loss: 0.2669\n",
            "Epoch 98/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0462 - val_accuracy: 0.9781 - val_loss: 0.2250\n",
            "Epoch 99/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9812 - val_loss: 0.2320\n",
            "Epoch 100/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 0.9781 - val_loss: 0.2777\n",
            "Epoch 101/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9959 - loss: 0.0074 - val_accuracy: 0.9812 - val_loss: 0.2738\n",
            "Epoch 102/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0502 - val_accuracy: 0.9797 - val_loss: 0.2227\n",
            "Epoch 103/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0155 - val_accuracy: 0.9797 - val_loss: 0.2551\n",
            "Epoch 104/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0068 - val_accuracy: 0.9781 - val_loss: 0.3440\n",
            "Epoch 105/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0154 - val_accuracy: 0.9750 - val_loss: 0.3602\n",
            "Epoch 106/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9734 - val_loss: 0.3186\n",
            "Epoch 107/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0088 - val_accuracy: 0.9703 - val_loss: 0.2344\n",
            "Epoch 108/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9972 - loss: 0.0075 - val_accuracy: 0.9812 - val_loss: 0.0901\n",
            "Epoch 109/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9926 - loss: 0.0569 - val_accuracy: 0.9719 - val_loss: 0.1620\n",
            "Epoch 110/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0094 - val_accuracy: 0.9781 - val_loss: 0.1566\n",
            "Epoch 111/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0199 - val_accuracy: 0.9766 - val_loss: 0.1258\n",
            "Epoch 112/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0090 - val_accuracy: 0.9781 - val_loss: 0.1218\n",
            "Epoch 113/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9970 - loss: 0.0325 - val_accuracy: 0.9812 - val_loss: 0.1323\n",
            "Epoch 114/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0273 - val_accuracy: 0.9797 - val_loss: 0.1241\n",
            "Epoch 115/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0021 - val_accuracy: 0.9766 - val_loss: 0.1351\n",
            "Epoch 116/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0069 - val_accuracy: 0.9844 - val_loss: 0.1247\n",
            "Epoch 117/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0026 - val_accuracy: 0.9812 - val_loss: 0.1267\n",
            "Epoch 118/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0035 - val_accuracy: 0.9812 - val_loss: 0.1323\n",
            "Epoch 119/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9975 - loss: 0.0058 - val_accuracy: 0.9828 - val_loss: 0.1107\n",
            "Epoch 120/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0092 - val_accuracy: 0.9812 - val_loss: 0.1107\n",
            "Epoch 121/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.9844 - val_loss: 0.1035\n",
            "Epoch 122/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.9844 - val_loss: 0.0968\n",
            "Epoch 123/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9844 - val_loss: 0.0955\n",
            "Epoch 124/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9844 - val_loss: 0.1044\n",
            "Epoch 125/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0021 - val_accuracy: 0.9828 - val_loss: 0.1076\n",
            "Epoch 126/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0049 - val_accuracy: 0.9812 - val_loss: 0.1291\n",
            "Epoch 127/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9750 - val_loss: 0.1588\n",
            "Epoch 128/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9906 - val_loss: 0.0898\n",
            "Epoch 129/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.9131e-04 - val_accuracy: 0.9859 - val_loss: 0.1018\n",
            "Epoch 130/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9844 - val_loss: 0.1246\n",
            "Epoch 131/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9989 - loss: 0.0015 - val_accuracy: 0.9875 - val_loss: 0.0994\n",
            "Epoch 132/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9970 - loss: 0.0059 - val_accuracy: 0.9734 - val_loss: 0.1608\n",
            "Epoch 133/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9812 - val_loss: 0.1328\n",
            "Epoch 134/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0020 - val_accuracy: 0.9797 - val_loss: 0.1259\n",
            "Epoch 135/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.9859 - val_loss: 0.1275\n",
            "Epoch 136/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.9734 - val_loss: 0.1678\n",
            "Epoch 137/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9976 - loss: 0.0040 - val_accuracy: 0.9844 - val_loss: 0.1193\n",
            "Epoch 138/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0021 - val_accuracy: 0.9766 - val_loss: 0.1618\n",
            "Epoch 139/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0019 - val_accuracy: 0.9828 - val_loss: 0.1571\n",
            "Epoch 140/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 5.2698e-04 - val_accuracy: 0.9781 - val_loss: 0.1783\n",
            "Epoch 141/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0028 - val_accuracy: 0.9781 - val_loss: 0.1659\n",
            "Epoch 142/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 3.1208e-04 - val_accuracy: 0.9703 - val_loss: 0.2136\n",
            "Epoch 143/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0022 - val_accuracy: 0.9703 - val_loss: 0.2133\n",
            "Epoch 144/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0036 - val_accuracy: 0.9797 - val_loss: 0.1380\n",
            "Epoch 145/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 7.8575e-04 - val_accuracy: 0.9812 - val_loss: 0.1422\n",
            "Epoch 146/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 1.8895e-04 - val_accuracy: 0.9828 - val_loss: 0.1430\n",
            "Epoch 147/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 8.6688e-04 - val_accuracy: 0.9828 - val_loss: 0.1474\n",
            "Epoch 148/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9844 - val_loss: 0.1441\n",
            "Epoch 149/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 1.7340e-04 - val_accuracy: 0.9875 - val_loss: 0.1282\n",
            "Epoch 150/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0151 - val_accuracy: 0.9719 - val_loss: 0.3183\n",
            "Epoch 151/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.0562 - val_accuracy: 0.9781 - val_loss: 0.1635\n",
            "Epoch 152/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0084 - val_accuracy: 0.9828 - val_loss: 0.1312\n",
            "Epoch 153/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.0089 - val_accuracy: 0.9828 - val_loss: 0.1265\n",
            "Epoch 154/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0060 - val_accuracy: 0.9844 - val_loss: 0.1287\n",
            "Epoch 155/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9844 - val_loss: 0.1316\n",
            "Epoch 156/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0088 - val_accuracy: 0.9797 - val_loss: 0.1808\n",
            "Epoch 157/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.9812 - val_loss: 0.1767\n",
            "Epoch 158/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9844 - val_loss: 0.1343\n",
            "Epoch 159/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0060 - val_accuracy: 0.9797 - val_loss: 0.1564\n",
            "Epoch 160/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.9797 - val_loss: 0.1372\n",
            "Epoch 161/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0042 - val_accuracy: 0.9828 - val_loss: 0.1353\n",
            "Epoch 162/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0864e-04 - val_accuracy: 0.9812 - val_loss: 0.1866\n",
            "Epoch 163/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0035 - val_accuracy: 0.9812 - val_loss: 0.1864\n",
            "Epoch 164/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.0027e-05 - val_accuracy: 0.9812 - val_loss: 0.1854\n",
            "Epoch 165/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.3006e-04 - val_accuracy: 0.9812 - val_loss: 0.1868\n",
            "Epoch 166/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 5.3164e-04 - val_accuracy: 0.9812 - val_loss: 0.1936\n",
            "Epoch 167/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0026 - val_accuracy: 0.9766 - val_loss: 0.2007\n",
            "Epoch 168/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0014 - val_accuracy: 0.9812 - val_loss: 0.2060\n",
            "Epoch 169/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 9.8569e-05 - val_accuracy: 0.9828 - val_loss: 0.1992\n",
            "Epoch 170/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0026 - val_accuracy: 0.9812 - val_loss: 0.2118\n",
            "Epoch 171/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9812 - val_loss: 0.2679\n",
            "Epoch 172/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0031 - val_accuracy: 0.9781 - val_loss: 0.2800\n",
            "Epoch 173/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0031 - val_accuracy: 0.9766 - val_loss: 0.3695\n",
            "Epoch 174/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 5.2176e-04 - val_accuracy: 0.9672 - val_loss: 0.4487\n",
            "Epoch 175/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9971 - loss: 0.0067 - val_accuracy: 0.9750 - val_loss: 0.3622\n",
            "Epoch 176/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0346 - val_accuracy: 0.9719 - val_loss: 0.2937\n",
            "Epoch 177/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0227 - val_accuracy: 0.9500 - val_loss: 0.4594\n",
            "Epoch 178/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0191 - val_accuracy: 0.9688 - val_loss: 0.1964\n",
            "Epoch 179/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0080 - val_accuracy: 0.9812 - val_loss: 0.1007\n",
            "Epoch 180/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0032 - val_accuracy: 0.9734 - val_loss: 0.1502\n",
            "Epoch 181/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9976 - loss: 0.0050 - val_accuracy: 0.9703 - val_loss: 0.1462\n",
            "Epoch 182/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9965 - loss: 0.0059 - val_accuracy: 0.9797 - val_loss: 0.1036\n",
            "Epoch 183/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9781 - val_loss: 0.1237\n",
            "Epoch 184/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9781 - val_loss: 0.1336\n",
            "Epoch 185/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0120 - val_accuracy: 0.9734 - val_loss: 0.1743\n",
            "Epoch 186/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9960 - loss: 0.0086 - val_accuracy: 0.9734 - val_loss: 0.1676\n",
            "Epoch 187/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9987 - loss: 0.0113 - val_accuracy: 0.9734 - val_loss: 0.1865\n",
            "Epoch 188/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 0.0086 - val_accuracy: 0.9734 - val_loss: 0.2223\n",
            "Epoch 189/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 0.0025 - val_accuracy: 0.9656 - val_loss: 0.3114\n",
            "Epoch 190/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0361 - val_accuracy: 0.9688 - val_loss: 0.3411\n",
            "Epoch 191/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9625 - val_loss: 0.2813\n",
            "Epoch 192/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.9609 - val_loss: 0.3732\n",
            "Epoch 193/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0048 - val_accuracy: 0.9656 - val_loss: 0.3132\n",
            "Epoch 194/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0079 - val_accuracy: 0.9563 - val_loss: 0.4082\n",
            "Epoch 195/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0032 - val_accuracy: 0.9703 - val_loss: 0.3174\n",
            "Epoch 196/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9688 - val_loss: 0.3246\n",
            "Epoch 197/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 6.6049e-04 - val_accuracy: 0.9672 - val_loss: 0.3291\n",
            "Epoch 198/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9734 - val_loss: 0.3695\n",
            "Epoch 199/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0070 - val_accuracy: 0.9750 - val_loss: 0.3122\n",
            "Epoch 200/200\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9734 - val_loss: 0.3239\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a423e8d35c0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs5e7kYTb_VW",
        "outputId": "12e189ae-5a2f-4dae-ed45-e12fc61d1d5d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba[10]"
      ],
      "metadata": {
        "id": "CFL4TG1-dUEM",
        "outputId": "e9ee72e7-3977-4387-dcb7-7caca39a1c55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.1084198e-12, 9.9999988e-01, 9.6192366e-08], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_labels = np.argmax(y_pred_proba, axis=1)"
      ],
      "metadata": {
        "id": "BG8YleQddY9B"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = predict_labels"
      ],
      "metadata": {
        "id": "OeQXXi9sdbwP"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[10]"
      ],
      "metadata": {
        "id": "kOUwq_BHdeHG",
        "outputId": "92e3cb14-9ad4-4481-a09d-79e5eeac39ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(1)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "L_gSspEXdgWk"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "ERJOlQNteM90",
        "outputId": "737773af-26f8-4d3f-840d-4d7ad8d8cd08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[204   0   2]\n",
            " [  0 216   3]\n",
            " [  9   3 203]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "vnFgXNB0ePhY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')"
      ],
      "metadata": {
        "id": "N2RYQekLeR5T",
        "outputId": "70cd014d-a96f-4bc1-8242-696439948a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "VZ-emUG-eTzN",
        "outputId": "77ef4646-a225-4b02-84ef-444f37144011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       206\n",
            "           1       0.99      0.99      0.99       219\n",
            "           2       0.98      0.94      0.96       215\n",
            "\n",
            "    accuracy                           0.97       640\n",
            "   macro avg       0.97      0.97      0.97       640\n",
            "weighted avg       0.97      0.97      0.97       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ZNfHKyNeYA6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}